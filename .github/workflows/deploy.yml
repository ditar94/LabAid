name: Deploy Pipeline

on:
  push:
    branches: [beta]
    paths-ignore:
      - "**.md"
      - "docs/**"
      - "LICENSE"
      - ".gitignore"

concurrency:
  group: deploy-pipeline
  cancel-in-progress: true

env:
  GCP_PROJECT: labaid-prod
  GCP_REGION: us-central1
  REPO_NAME: labaid

jobs:
  # ── Tests ────────────────────────────────────────────────────────────────────
  test:
    name: Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip
          cache-dependency-path: backend/requirements.txt

      - name: Install Python dependencies
        run: pip install -r backend/requirements.txt

      - name: Check Python dependencies for vulnerabilities
        run: |
          pip install pip-audit
          echo "Scanning Python dependencies for vulnerabilities..."
          pip-audit --strict --vulnerability-service osv || {
            echo "::warning::Python dependency vulnerabilities found. Review and update requirements.txt"
            # Don't fail on vulnerabilities without fixes available
            pip-audit --vulnerability-service osv
          }

      - name: Check for destructive migrations
        run: |
          cd backend/alembic/versions

          # Dangerous SQL patterns that could cause data loss
          DANGEROUS_PATTERNS="DROP COLUMN|DROP TABLE|DROP INDEX|ALTER COLUMN.*TYPE|RENAME COLUMN|TRUNCATE"

          # Check all migration files
          FOUND_DANGEROUS=""
          for file in *.py; do
            [ -f "$file" ] || continue

            # Look for dangerous operations (case-insensitive)
            MATCHES=$(grep -iE "$DANGEROUS_PATTERNS" "$file" 2>/dev/null | grep -v "^#" | grep -v "# DESTRUCTIVE:" || true)

            if [ -n "$MATCHES" ]; then
              # Check if there's an acknowledgment comment
              if ! grep -q "# DESTRUCTIVE: acknowledged" "$file"; then
                FOUND_DANGEROUS="$FOUND_DANGEROUS

          FILE: $file
          $MATCHES"
              fi
            fi
          done

          if [ -n "$FOUND_DANGEROUS" ]; then
            echo ""
            echo "::error::Destructive migration operations detected!"
            echo "$FOUND_DANGEROUS"
            echo ""
            echo "These operations can cause DATA LOSS in production."
            echo ""
            echo "If intentional, add this comment to the migration file:"
            echo "  # DESTRUCTIVE: acknowledged - [reason for data loss]"
            echo ""
            exit 1
          fi

          echo "No unacknowledged destructive migrations found."

      - name: Validate migrations against Postgres
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          SECRET_KEY: test-secret-key
        run: |
          cd backend
          echo "Running alembic migrations..."
          alembic upgrade head

      - name: Check for missing migrations
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          SECRET_KEY: test-secret-key
        run: |
          cd backend
          echo "Checking if models match migrations..."
          if ! alembic check 2>&1 | grep -q "No new upgrade operations detected"; then
            echo ""
            echo "::error::Models have changed but no migration was created!"
            echo ""
            echo "Run locally:"
            echo "  cd backend && alembic revision --autogenerate -m 'description'"
            echo ""
            echo "Then commit the new migration file and push again."
            exit 1
          fi
          echo "Models and migrations are in sync."

      - name: Test migration rollback
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          SECRET_KEY: test-secret-key
        run: |
          cd backend
          echo "Testing migration downgrade..."
          alembic downgrade -1 || { echo "::error::Migration downgrade failed! Ensure downgrade() is implemented."; exit 1; }
          echo "Testing migration upgrade again..."
          alembic upgrade head || { echo "::error::Migration upgrade after downgrade failed!"; exit 1; }
          echo "Migration rollback test passed."

      - name: Verify models load correctly
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          SECRET_KEY: test-secret-key
        run: |
          cd backend
          python -c "
          from app.models import *
          from app.main import app
          print('All models and routes loaded successfully')
          "

      - name: Run backend tests
        env:
          SECRET_KEY: test-secret-key
          DATABASE_URL: postgresql://test:test@localhost:5432/test
        run: python -m pytest backend/tests/ -v

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Install Node dependencies
        run: cd frontend && npm ci

      - name: Check Node dependencies for vulnerabilities
        run: |
          cd frontend
          echo "Scanning Node dependencies for vulnerabilities..."
          npm audit --audit-level=high || {
            echo "::warning::Node dependency vulnerabilities found. Run 'npm audit fix' to resolve."
          }

      - name: TypeScript check
        run: cd frontend && npx tsc --noEmit -p tsconfig.app.json

  # ── Start nonprod database ──────────────────────────────────────────────────
  start-nonprod-db:
    name: Start Nonprod Database
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Start nonprod Cloud SQL instance if stopped
        run: |
          STATE=$(gcloud sql instances describe labaid-db-nonprod --project ${GCP_PROJECT} --format='value(state)')
          if [ "$STATE" = "RUNNABLE" ]; then
            echo "Instance already running, skipping start"
            exit 0
          fi
          echo "Instance is stopped (state: $STATE), starting..."
          for i in $(seq 1 10); do
            if gcloud sql instances patch labaid-db-nonprod \
              --activation-policy=ALWAYS \
              --project ${GCP_PROJECT} 2>&1; then
              echo "Start command succeeded"
              break
            fi
            echo "Attempt $i failed (likely concurrent operation), retrying in 30s..."
            sleep 30
          done

      - name: Wait for instance to be ready
        run: |
          for i in $(seq 1 30); do
            STATE=$(gcloud sql instances describe labaid-db-nonprod --project ${GCP_PROJECT} --format='value(state)')
            if [ "$STATE" = "RUNNABLE" ]; then
              echo "Instance is ready"
              exit 0
            fi
            echo "Waiting for instance... (state: $STATE)"
            sleep 10
          done
          echo "Timeout waiting for instance"
          exit 1

  # ── Beta (auto after tests pass) ────────────────────────────────────────────
  beta-backend:
    name: Deploy Backend (Beta)
    needs: [test, start-nonprod-db]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker auth
        run: gcloud auth configure-docker ${GCP_REGION}-docker.pkg.dev --quiet

      - uses: docker/setup-buildx-action@v3

      - name: Build and push image
        uses: docker/build-push-action@v5
        with:
          context: backend
          file: backend/Dockerfile.prod
          push: true
          tags: |
            ${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.REPO_NAME }}/backend:beta
            ${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.REPO_NAME }}/backend:beta-${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy labaid-backend-beta \
            --image ${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT}/${REPO_NAME}/backend:beta-${GITHUB_SHA} \
            --region ${GCP_REGION} \
            --platform managed \
            --allow-unauthenticated \
            --service-account cloud-run-backend@${GCP_PROJECT}.iam.gserviceaccount.com \
            --add-cloudsql-instances ${GCP_PROJECT}:${GCP_REGION}:labaid-db-nonprod \
            --set-env-vars "COOKIE_SECURE=True,COOKIE_SAMESITE=lax,S3_ENDPOINT_URL=https://storage.googleapis.com,S3_USE_PATH_STYLE=False,GCP_PROJECT=${GCP_PROJECT},EMAIL_BACKEND=console,APP_URL=https://beta.labaid.io" \
            --set-secrets "SECRET_KEY=SECRET_KEY:latest,DATABASE_URL=DATABASE_URL_BETA:latest,DATABASE_URL_MIGRATE=DATABASE_URL_BETA_MIGRATE:latest,S3_ACCESS_KEY=S3_ACCESS_KEY:latest,S3_SECRET_KEY=S3_SECRET_KEY:latest,S3_BUCKET=S3_BUCKET:latest,CORS_ORIGINS=CORS_ORIGINS:latest,COOKIE_DOMAIN=COOKIE_DOMAIN:latest" \
            --memory 512Mi \
            --cpu 1 \
            --min-instances 0 \
            --max-instances 3 \
            --port 8080 \
            --project ${GCP_PROJECT}

      - name: Health check
        run: |
          URL=$(gcloud run services describe labaid-backend-beta --region=${GCP_REGION} --project=${GCP_PROJECT} --format='value(status.url)')
          for i in 1 2 3; do
            RESPONSE=$(curl -sf "${URL}/api/health" 2>&1) && break
            echo "Attempt $i failed, retrying in 10s..."
            sleep 10
          done
          echo "$RESPONSE"
          echo "$RESPONSE" | grep -q '"status":"ok"' || { echo "Health check failed!"; exit 1; }

  beta-frontend:
    name: Deploy Frontend (Beta)
    needs: [test, start-nonprod-db]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Build frontend
        env:
          VITE_APP_ENV: beta
          VITE_GIT_SHA: ${{ github.sha }}
        run: cd frontend && npm ci && npm run build

      - name: Deploy to Firebase Hosting
        run: npx firebase-tools deploy --only hosting:labaid-beta --project ${GCP_PROJECT}

  # ── Staging (requires approval) ─────────────────────────────────────────────
  staging-backend:
    name: Deploy Backend (Staging)
    needs: [beta-backend, beta-frontend]
    runs-on: ubuntu-latest
    environment: staging
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker auth
        run: gcloud auth configure-docker ${GCP_REGION}-docker.pkg.dev --quiet

      - uses: docker/setup-buildx-action@v3

      - name: Build and push image
        uses: docker/build-push-action@v5
        with:
          context: backend
          file: backend/Dockerfile.prod
          push: true
          tags: |
            ${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.REPO_NAME }}/backend:staging
            ${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.REPO_NAME }}/backend:staging-${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy labaid-backend-staging \
            --image ${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT}/${REPO_NAME}/backend:staging-${GITHUB_SHA} \
            --region ${GCP_REGION} \
            --platform managed \
            --allow-unauthenticated \
            --service-account cloud-run-backend@${GCP_PROJECT}.iam.gserviceaccount.com \
            --add-cloudsql-instances ${GCP_PROJECT}:${GCP_REGION}:labaid-db-nonprod \
            --set-env-vars "COOKIE_SECURE=True,COOKIE_SAMESITE=lax,S3_ENDPOINT_URL=https://storage.googleapis.com,S3_USE_PATH_STYLE=False,GCP_PROJECT=${GCP_PROJECT},EMAIL_BACKEND=resend,APP_URL=https://staging.labaid.io" \
            --set-secrets "SECRET_KEY=SECRET_KEY:latest,DATABASE_URL=DATABASE_URL_BETA:latest,DATABASE_URL_MIGRATE=DATABASE_URL_BETA_MIGRATE:latest,S3_ACCESS_KEY=S3_ACCESS_KEY:latest,S3_SECRET_KEY=S3_SECRET_KEY:latest,S3_BUCKET=S3_BUCKET:latest,CORS_ORIGINS=CORS_ORIGINS:latest,COOKIE_DOMAIN=COOKIE_DOMAIN:latest,RESEND_API_KEY=RESEND_API_KEY:latest" \
            --memory 512Mi \
            --cpu 1 \
            --min-instances 0 \
            --max-instances 3 \
            --port 8080 \
            --project ${GCP_PROJECT}

      - name: Health check
        run: |
          URL=$(gcloud run services describe labaid-backend-staging --region=${GCP_REGION} --project=${GCP_PROJECT} --format='value(status.url)')
          for i in 1 2 3; do
            RESPONSE=$(curl -sf "${URL}/api/health" 2>&1) && break
            echo "Attempt $i failed, retrying in 10s..."
            sleep 10
          done
          echo "$RESPONSE"
          echo "$RESPONSE" | grep -q '"status":"ok"' || { echo "Health check failed!"; exit 1; }

  staging-frontend:
    name: Deploy Frontend (Staging)
    needs: [beta-backend, beta-frontend]
    runs-on: ubuntu-latest
    environment: staging
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Build frontend
        env:
          VITE_APP_ENV: staging
          VITE_GIT_SHA: ${{ github.sha }}
        run: cd frontend && npm ci && npm run build

      - name: Deploy to Firebase Hosting
        run: npx firebase-tools deploy --only hosting:labaid-staging --project ${GCP_PROJECT}

  # ── Production (requires approval) ──────────────────────────────────────────
  prod-backend:
    name: Deploy Backend (Production)
    needs: [staging-backend, staging-frontend]
    runs-on: ubuntu-latest
    environment: production
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Create database backup
        run: |
          gcloud sql backups create \
            --instance=labaid-db-prod \
            --description="Pre-deploy backup $(date -u +%Y%m%d-%H%M%S)" \
            --project ${GCP_PROJECT}

      - name: Configure Docker auth
        run: gcloud auth configure-docker ${GCP_REGION}-docker.pkg.dev --quiet

      - uses: docker/setup-buildx-action@v3

      - name: Build and push image
        uses: docker/build-push-action@v5
        with:
          context: backend
          file: backend/Dockerfile.prod
          push: true
          tags: |
            ${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.REPO_NAME }}/backend:latest
            ${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.REPO_NAME }}/backend:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy labaid-backend \
            --image ${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT}/${REPO_NAME}/backend:${GITHUB_SHA} \
            --region ${GCP_REGION} \
            --platform managed \
            --allow-unauthenticated \
            --service-account cloud-run-backend@${GCP_PROJECT}.iam.gserviceaccount.com \
            --add-cloudsql-instances ${GCP_PROJECT}:${GCP_REGION}:labaid-db-prod \
            --set-env-vars "COOKIE_SECURE=True,COOKIE_SAMESITE=lax,S3_ENDPOINT_URL=https://storage.googleapis.com,S3_USE_PATH_STYLE=False,GCP_PROJECT=${GCP_PROJECT},EMAIL_BACKEND=resend,APP_URL=https://labaid.io" \
            --set-secrets "SECRET_KEY=SECRET_KEY:latest,DATABASE_URL=DATABASE_URL:latest,DATABASE_URL_MIGRATE=DATABASE_URL_MIGRATE:latest,S3_ACCESS_KEY=S3_ACCESS_KEY:latest,S3_SECRET_KEY=S3_SECRET_KEY:latest,S3_BUCKET=S3_BUCKET:latest,CORS_ORIGINS=CORS_ORIGINS:latest,COOKIE_DOMAIN=COOKIE_DOMAIN:latest,RESEND_API_KEY=RESEND_API_KEY:latest" \
            --memory 512Mi \
            --cpu 1 \
            --min-instances 0 \
            --max-instances 3 \
            --port 8080 \
            --project ${GCP_PROJECT}

      - name: Health check
        run: |
          URL=$(gcloud run services describe labaid-backend --region=${GCP_REGION} --project=${GCP_PROJECT} --format='value(status.url)')
          for i in 1 2 3; do
            RESPONSE=$(curl -sf "${URL}/api/health" 2>&1) && break
            echo "Attempt $i failed, retrying in 10s..."
            sleep 10
          done
          echo "$RESPONSE"
          echo "$RESPONSE" | grep -q '"status":"ok"' || { echo "Health check failed!"; exit 1; }

  prod-frontend:
    name: Deploy Frontend (Production)
    needs: [staging-backend, staging-frontend]
    runs-on: ubuntu-latest
    environment: production
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Build frontend
        env:
          VITE_APP_ENV: production
          VITE_GIT_SHA: ${{ github.sha }}
        run: cd frontend && npm ci && npm run build

      - name: Deploy to Firebase Hosting
        run: npx firebase-tools deploy --only hosting:labaid-prod --project ${GCP_PROJECT}

  # ── Sync main + tag release (auto after production) ─────────────────────────
  sync-main:
    name: Sync main & tag release
    needs: [prod-backend, prod-frontend]
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Update main to match beta
        run: |
          git push origin origin/beta:refs/heads/main --force

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip
          cache-dependency-path: backend/requirements.txt

      - name: Install Alembic
        run: pip install -r backend/requirements.txt

      - name: Create release tag
        env:
          SECRET_KEY: unused
          DATABASE_URL: "sqlite://"
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          VERSION="v$(date -u +%Y.%m.%d)"
          MIGRATION_HEAD=$(cd backend && python -c "from alembic.config import Config; from alembic.script import ScriptDirectory; print(ScriptDirectory.from_config(Config('alembic.ini')).get_current_head())")
          SHORT_SHA="${GITHUB_SHA::8}"

          # Append a counter if tag already exists (multiple deploys same day)
          TAG="$VERSION"
          COUNTER=1
          while git rev-parse "$TAG" >/dev/null 2>&1; do
            COUNTER=$((COUNTER + 1))
            TAG="${VERSION}.${COUNTER}"
          done

          git tag -a "$TAG" -m "Release $TAG

          Commit: ${GITHUB_SHA}
          Migration head: ${MIGRATION_HEAD}"
          git push origin "$TAG"
